{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z1D04CKlVn4z"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ioLxpAm1XIhT",
        "outputId": "b6d54d92-e360-44c2-970e-7f021d7d0da6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.935192</td>\n",
              "      <td>0.766490</td>\n",
              "      <td>0.881365</td>\n",
              "      <td>0.313023</td>\n",
              "      <td>0.763439</td>\n",
              "      <td>0.267669</td>\n",
              "      <td>0.266815</td>\n",
              "      <td>0.786444</td>\n",
              "      <td>0.475312</td>\n",
              "      <td>0.510600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.561184</td>\n",
              "      <td>0.522992</td>\n",
              "      <td>0.663793</td>\n",
              "      <td>0.391253</td>\n",
              "      <td>0.585122</td>\n",
              "      <td>0.394557</td>\n",
              "      <td>0.418976</td>\n",
              "      <td>0.312697</td>\n",
              "      <td>0.005824</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.978542</td>\n",
              "      <td>0.770067</td>\n",
              "      <td>0.840298</td>\n",
              "      <td>0.271796</td>\n",
              "      <td>0.766120</td>\n",
              "      <td>0.262192</td>\n",
              "      <td>0.264875</td>\n",
              "      <td>0.786298</td>\n",
              "      <td>0.453981</td>\n",
              "      <td>0.505267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.557840</td>\n",
              "      <td>0.480237</td>\n",
              "      <td>0.666938</td>\n",
              "      <td>0.336440</td>\n",
              "      <td>0.587290</td>\n",
              "      <td>0.446013</td>\n",
              "      <td>0.416345</td>\n",
              "      <td>0.313423</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.935217</td>\n",
              "      <td>0.753118</td>\n",
              "      <td>0.868141</td>\n",
              "      <td>0.268766</td>\n",
              "      <td>0.762329</td>\n",
              "      <td>0.281122</td>\n",
              "      <td>0.270177</td>\n",
              "      <td>0.788042</td>\n",
              "      <td>0.410603</td>\n",
              "      <td>0.513018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565477</td>\n",
              "      <td>0.546030</td>\n",
              "      <td>0.678939</td>\n",
              "      <td>0.289354</td>\n",
              "      <td>0.559515</td>\n",
              "      <td>0.402727</td>\n",
              "      <td>0.415489</td>\n",
              "      <td>0.311911</td>\n",
              "      <td>0.014739</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.941878</td>\n",
              "      <td>0.765304</td>\n",
              "      <td>0.868484</td>\n",
              "      <td>0.213661</td>\n",
              "      <td>0.765647</td>\n",
              "      <td>0.275559</td>\n",
              "      <td>0.266803</td>\n",
              "      <td>0.789434</td>\n",
              "      <td>0.414999</td>\n",
              "      <td>0.507585</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559734</td>\n",
              "      <td>0.510277</td>\n",
              "      <td>0.662607</td>\n",
              "      <td>0.223826</td>\n",
              "      <td>0.614245</td>\n",
              "      <td>0.389197</td>\n",
              "      <td>0.417669</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0.004807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.938617</td>\n",
              "      <td>0.776520</td>\n",
              "      <td>0.864251</td>\n",
              "      <td>0.269796</td>\n",
              "      <td>0.762975</td>\n",
              "      <td>0.263984</td>\n",
              "      <td>0.268968</td>\n",
              "      <td>0.782484</td>\n",
              "      <td>0.490950</td>\n",
              "      <td>0.524303</td>\n",
              "      <td>...</td>\n",
              "      <td>0.561327</td>\n",
              "      <td>0.547271</td>\n",
              "      <td>0.663392</td>\n",
              "      <td>0.401270</td>\n",
              "      <td>0.566343</td>\n",
              "      <td>0.507497</td>\n",
              "      <td>0.420561</td>\n",
              "      <td>0.317490</td>\n",
              "      <td>0.002724</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>0.756448</td>\n",
              "      <td>0.873531</td>\n",
              "      <td>0.666991</td>\n",
              "      <td>0.160317</td>\n",
              "      <td>0.729603</td>\n",
              "      <td>0.236810</td>\n",
              "      <td>0.235393</td>\n",
              "      <td>0.863749</td>\n",
              "      <td>0.528729</td>\n",
              "      <td>0.598850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.564920</td>\n",
              "      <td>0.515249</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.313600</td>\n",
              "      <td>0.658558</td>\n",
              "      <td>0.466291</td>\n",
              "      <td>0.433929</td>\n",
              "      <td>0.329840</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>0.945845</td>\n",
              "      <td>0.766677</td>\n",
              "      <td>0.872678</td>\n",
              "      <td>0.219189</td>\n",
              "      <td>0.771561</td>\n",
              "      <td>0.273661</td>\n",
              "      <td>0.265504</td>\n",
              "      <td>0.788548</td>\n",
              "      <td>0.482925</td>\n",
              "      <td>0.488530</td>\n",
              "      <td>...</td>\n",
              "      <td>0.564933</td>\n",
              "      <td>0.553154</td>\n",
              "      <td>0.665619</td>\n",
              "      <td>0.245298</td>\n",
              "      <td>0.543855</td>\n",
              "      <td>0.360884</td>\n",
              "      <td>0.417775</td>\n",
              "      <td>0.312038</td>\n",
              "      <td>0.000965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>0.990905</td>\n",
              "      <td>0.764080</td>\n",
              "      <td>0.781102</td>\n",
              "      <td>0.227202</td>\n",
              "      <td>0.783425</td>\n",
              "      <td>0.293496</td>\n",
              "      <td>0.263547</td>\n",
              "      <td>0.792985</td>\n",
              "      <td>0.477677</td>\n",
              "      <td>0.498692</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565220</td>\n",
              "      <td>0.537005</td>\n",
              "      <td>0.664877</td>\n",
              "      <td>0.468492</td>\n",
              "      <td>0.592823</td>\n",
              "      <td>0.411176</td>\n",
              "      <td>0.416593</td>\n",
              "      <td>0.312585</td>\n",
              "      <td>0.002642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>0.954209</td>\n",
              "      <td>0.772856</td>\n",
              "      <td>0.849587</td>\n",
              "      <td>0.282508</td>\n",
              "      <td>0.763172</td>\n",
              "      <td>0.269291</td>\n",
              "      <td>0.261175</td>\n",
              "      <td>0.792671</td>\n",
              "      <td>0.476287</td>\n",
              "      <td>0.500464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565755</td>\n",
              "      <td>0.547353</td>\n",
              "      <td>0.663008</td>\n",
              "      <td>0.398836</td>\n",
              "      <td>0.545958</td>\n",
              "      <td>0.514746</td>\n",
              "      <td>0.418520</td>\n",
              "      <td>0.315245</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>0.949232</td>\n",
              "      <td>0.765256</td>\n",
              "      <td>0.849601</td>\n",
              "      <td>0.229488</td>\n",
              "      <td>0.765632</td>\n",
              "      <td>0.256488</td>\n",
              "      <td>0.274963</td>\n",
              "      <td>0.780938</td>\n",
              "      <td>0.479528</td>\n",
              "      <td>0.489782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565688</td>\n",
              "      <td>0.540031</td>\n",
              "      <td>0.671029</td>\n",
              "      <td>0.383420</td>\n",
              "      <td>0.551319</td>\n",
              "      <td>0.291786</td>\n",
              "      <td>0.416466</td>\n",
              "      <td>0.313401</td>\n",
              "      <td>0.008446</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0       0.935192  0.766490  0.881365  0.313023  0.763439  0.267669  0.266815   \n",
              "1       0.978542  0.770067  0.840298  0.271796  0.766120  0.262192  0.264875   \n",
              "2       0.935217  0.753118  0.868141  0.268766  0.762329  0.281122  0.270177   \n",
              "3       0.941878  0.765304  0.868484  0.213661  0.765647  0.275559  0.266803   \n",
              "4       0.938617  0.776520  0.864251  0.269796  0.762975  0.263984  0.268968   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "284802  0.756448  0.873531  0.666991  0.160317  0.729603  0.236810  0.235393   \n",
              "284803  0.945845  0.766677  0.872678  0.219189  0.771561  0.273661  0.265504   \n",
              "284804  0.990905  0.764080  0.781102  0.227202  0.783425  0.293496  0.263547   \n",
              "284805  0.954209  0.772856  0.849587  0.282508  0.763172  0.269291  0.261175   \n",
              "284806  0.949232  0.765256  0.849601  0.229488  0.765632  0.256488  0.274963   \n",
              "\n",
              "              V8        V9       V10  ...       V21       V22       V23  \\\n",
              "0       0.786444  0.475312  0.510600  ...  0.561184  0.522992  0.663793   \n",
              "1       0.786298  0.453981  0.505267  ...  0.557840  0.480237  0.666938   \n",
              "2       0.788042  0.410603  0.513018  ...  0.565477  0.546030  0.678939   \n",
              "3       0.789434  0.414999  0.507585  ...  0.559734  0.510277  0.662607   \n",
              "4       0.782484  0.490950  0.524303  ...  0.561327  0.547271  0.663392   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "284802  0.863749  0.528729  0.598850  ...  0.564920  0.515249  0.680500   \n",
              "284803  0.788548  0.482925  0.488530  ...  0.564933  0.553154  0.665619   \n",
              "284804  0.792985  0.477677  0.498692  ...  0.565220  0.537005  0.664877   \n",
              "284805  0.792671  0.476287  0.500464  ...  0.565755  0.547353  0.663008   \n",
              "284806  0.780938  0.479528  0.489782  ...  0.565688  0.540031  0.671029   \n",
              "\n",
              "             V24       V25       V26       V27       V28    Amount  class  \n",
              "0       0.391253  0.585122  0.394557  0.418976  0.312697  0.005824      0  \n",
              "1       0.336440  0.587290  0.446013  0.416345  0.313423  0.000105      0  \n",
              "2       0.289354  0.559515  0.402727  0.415489  0.311911  0.014739      0  \n",
              "3       0.223826  0.614245  0.389197  0.417669  0.314371  0.004807      0  \n",
              "4       0.401270  0.566343  0.507497  0.420561  0.317490  0.002724      0  \n",
              "...          ...       ...       ...       ...       ...       ...    ...  \n",
              "284802  0.313600  0.658558  0.466291  0.433929  0.329840  0.000030      0  \n",
              "284803  0.245298  0.543855  0.360884  0.417775  0.312038  0.000965      0  \n",
              "284804  0.468492  0.592823  0.411176  0.416593  0.312585  0.002642      0  \n",
              "284805  0.398836  0.545958  0.514746  0.418520  0.315245  0.000389      0  \n",
              "284806  0.383420  0.551319  0.291786  0.416466  0.313401  0.008446      0  \n",
              "\n",
              "[284807 rows x 30 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"../Resources/creditcardfraud_normalised.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh_Ln_lYXR55",
        "outputId": "5e14fd18-ad13-41cc-edb5-2f6fb132e224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class=0, Count=284315, Percentage=99.827%\n",
            "Class=1, Count=492, Percentage=0.173%\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "#\n",
        "target = df.values[:, -1]\n",
        "counter = Counter(target)\n",
        "for k,v in counter.items():\n",
        "  per = v/len(target)*100\n",
        "  print(\"Class=%d, Count=%d, Percentage=%.3f%%\" % (k,v, per))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Class_count = df[\"class\"].value_counts()\n",
        "Class_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label= Class_count.index\n",
        "count= Class_count.values\n",
        "color = ['Orange','Blue']\n",
        "explode = (0, 0.15)\n",
        "plt.figure(1, figsize=(15,7))\n",
        "plt.pie(count, labels=label, colors=color, autopct='%1.1f%%', explode=explode)\n",
        "plt.legend(loc = 2)\n",
        "plt.title('Class Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assign X and y values\n",
        "y = df[\"class\"].values\n",
        "X = df.drop(columns=\"class\").values   \n",
        "\n",
        "#Split the data into X_train, X_test, y_train, y_test\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "  Using cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/Farzana/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.9.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/Farzana/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/Farzana/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.21.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/Farzana/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Farzana/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn) (2.2.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "Successfully installed imbalanced-learn-0.10.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Oversampling Imbalanced Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.10.1\n"
          ]
        }
      ],
      "source": [
        "import imblearn\n",
        "print(imblearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define oversampling strategy\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 284315, 1: 284315})\n"
          ]
        }
      ],
      "source": [
        "# fit and apply the transform\n",
        "X_over, y_over = oversample.fit_resample(X, y)\n",
        "# summarize class distribution\n",
        "print(Counter(y_over))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into X_train, X_test, y_train, y_test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((426472, 29), (142158, 29))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit a Random Forests classifier to the data\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Step 1: Instantiate model\n",
        "clf = RandomForestClassifier(random_state=1, n_estimators=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=500, random_state=1)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit a Random Forests classifier to the data\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     71023\n",
            "           1       1.00      1.00      1.00     71135\n",
            "\n",
            "    accuracy                           1.00    142158\n",
            "   macro avg       1.00      1.00      1.00    142158\n",
            "weighted avg       1.00      1.00      1.00    142158\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Assess other metrics for this model in oversampled dataset\n",
        "y_true = y_test\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Undersampling Imbalanced Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "# define undersample strategy\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 284315, 1: 284315})\n"
          ]
        }
      ],
      "source": [
        "# fit and apply the transform\n",
        "X_under, y_under = undersample.fit_resample(X, y)\n",
        "# summarize class distribution\n",
        "print(Counter(y_over))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into X_train, X_test, y_train, y_test\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_under, y_under, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((738, 29), (246, 29))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the distribution of samples\n",
        "X_train1.shape, X_test1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Instantiate model\n",
        "clf_under = RandomForestClassifier(random_state=1, n_estimators=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=500, random_state=1)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit a Random Forests classifier to the undersampled data\n",
        "clf_under.fit(X_train1, y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93       126\n",
            "           1       0.97      0.87      0.92       120\n",
            "\n",
            "    accuracy                           0.92       246\n",
            "   macro avg       0.93      0.92      0.92       246\n",
            "weighted avg       0.93      0.92      0.92       246\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Assess other metrics for this model in undersampled dataset\n",
        "y_true1 = y_test1\n",
        "y_pred1 = clf_under.predict(X_test1)\n",
        "print(classification_report(y_true1, y_pred1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SMOTETomek - Random Under and Over sampled Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smote_tomek = SMOTETomek(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 284315, 1: 284315})\n"
          ]
        }
      ],
      "source": [
        "# fit and apply the transform\n",
        "X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
        "# summarize class distribution\n",
        "print(Counter(y_resampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into X_train, X_test, y_train, y_test\n",
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_resampled, y_resampled, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((426472, 29), (142158, 29))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the distribution of samples\n",
        "X_train0.shape, X_test0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit a Random Forests classifier to the data\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Step 1: Instantiate model\n",
        "clf_underover = RandomForestClassifier(random_state=1, n_estimators=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=500, random_state=1)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit a Random Forests classifier to the SMOTETomek_sampled data\n",
        "clf_underover.fit(X_train0, y_train0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     71023\n",
            "           1       1.00      1.00      1.00     71135\n",
            "\n",
            "    accuracy                           1.00    142158\n",
            "   macro avg       1.00      1.00      1.00    142158\n",
            "weighted avg       1.00      1.00      1.00    142158\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Assess other metrics for this model\n",
        "y_true0 = y_test0\n",
        "y_pred0 = clf_underover.predict(X_test0)\n",
        "print(classification_report(y_true0, y_pred0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
