{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "JkaOU29NklV1"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import sklearn as skl\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"creditcardfraud_normalised.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "GdagcrVik72N",
        "outputId": "053f0e35-2a58-4f58-9d57-1e0783836c64"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0       0.935192  0.766490  0.881365  0.313023  0.763439  0.267669  0.266815   \n",
              "1       0.978542  0.770067  0.840298  0.271796  0.766120  0.262192  0.264875   \n",
              "2       0.935217  0.753118  0.868141  0.268766  0.762329  0.281122  0.270177   \n",
              "3       0.941878  0.765304  0.868484  0.213661  0.765647  0.275559  0.266803   \n",
              "4       0.938617  0.776520  0.864251  0.269796  0.762975  0.263984  0.268968   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "284802  0.756448  0.873531  0.666991  0.160317  0.729603  0.236810  0.235393   \n",
              "284803  0.945845  0.766677  0.872678  0.219189  0.771561  0.273661  0.265504   \n",
              "284804  0.990905  0.764080  0.781102  0.227202  0.783425  0.293496  0.263547   \n",
              "284805  0.954209  0.772856  0.849587  0.282508  0.763172  0.269291  0.261175   \n",
              "284806  0.949232  0.765256  0.849601  0.229488  0.765632  0.256488  0.274963   \n",
              "\n",
              "              V8        V9       V10  ...       V21       V22       V23  \\\n",
              "0       0.786444  0.475312  0.510600  ...  0.561184  0.522992  0.663793   \n",
              "1       0.786298  0.453981  0.505267  ...  0.557840  0.480237  0.666938   \n",
              "2       0.788042  0.410603  0.513018  ...  0.565477  0.546030  0.678939   \n",
              "3       0.789434  0.414999  0.507585  ...  0.559734  0.510277  0.662607   \n",
              "4       0.782484  0.490950  0.524303  ...  0.561327  0.547271  0.663392   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "284802  0.863749  0.528729  0.598850  ...  0.564920  0.515249  0.680500   \n",
              "284803  0.788548  0.482925  0.488530  ...  0.564933  0.553154  0.665619   \n",
              "284804  0.792985  0.477677  0.498692  ...  0.565220  0.537005  0.664877   \n",
              "284805  0.792671  0.476287  0.500464  ...  0.565755  0.547353  0.663008   \n",
              "284806  0.780938  0.479528  0.489782  ...  0.565688  0.540031  0.671029   \n",
              "\n",
              "             V24       V25       V26       V27       V28    Amount  class  \n",
              "0       0.391253  0.585122  0.394557  0.418976  0.312697  0.005824      0  \n",
              "1       0.336440  0.587290  0.446013  0.416345  0.313423  0.000105      0  \n",
              "2       0.289354  0.559515  0.402727  0.415489  0.311911  0.014739      0  \n",
              "3       0.223826  0.614245  0.389197  0.417669  0.314371  0.004807      0  \n",
              "4       0.401270  0.566343  0.507497  0.420561  0.317490  0.002724      0  \n",
              "...          ...       ...       ...       ...       ...       ...    ...  \n",
              "284802  0.313600  0.658558  0.466291  0.433929  0.329840  0.000030      0  \n",
              "284803  0.245298  0.543855  0.360884  0.417775  0.312038  0.000965      0  \n",
              "284804  0.468492  0.592823  0.411176  0.416593  0.312585  0.002642      0  \n",
              "284805  0.398836  0.545958  0.514746  0.418520  0.315245  0.000389      0  \n",
              "284806  0.383420  0.551319  0.291786  0.416466  0.313401  0.008446      0  \n",
              "\n",
              "[284807 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0c0263e-482b-46ae-9417-11f358a9ea80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.935192</td>\n",
              "      <td>0.766490</td>\n",
              "      <td>0.881365</td>\n",
              "      <td>0.313023</td>\n",
              "      <td>0.763439</td>\n",
              "      <td>0.267669</td>\n",
              "      <td>0.266815</td>\n",
              "      <td>0.786444</td>\n",
              "      <td>0.475312</td>\n",
              "      <td>0.510600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.561184</td>\n",
              "      <td>0.522992</td>\n",
              "      <td>0.663793</td>\n",
              "      <td>0.391253</td>\n",
              "      <td>0.585122</td>\n",
              "      <td>0.394557</td>\n",
              "      <td>0.418976</td>\n",
              "      <td>0.312697</td>\n",
              "      <td>0.005824</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.978542</td>\n",
              "      <td>0.770067</td>\n",
              "      <td>0.840298</td>\n",
              "      <td>0.271796</td>\n",
              "      <td>0.766120</td>\n",
              "      <td>0.262192</td>\n",
              "      <td>0.264875</td>\n",
              "      <td>0.786298</td>\n",
              "      <td>0.453981</td>\n",
              "      <td>0.505267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.557840</td>\n",
              "      <td>0.480237</td>\n",
              "      <td>0.666938</td>\n",
              "      <td>0.336440</td>\n",
              "      <td>0.587290</td>\n",
              "      <td>0.446013</td>\n",
              "      <td>0.416345</td>\n",
              "      <td>0.313423</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.935217</td>\n",
              "      <td>0.753118</td>\n",
              "      <td>0.868141</td>\n",
              "      <td>0.268766</td>\n",
              "      <td>0.762329</td>\n",
              "      <td>0.281122</td>\n",
              "      <td>0.270177</td>\n",
              "      <td>0.788042</td>\n",
              "      <td>0.410603</td>\n",
              "      <td>0.513018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565477</td>\n",
              "      <td>0.546030</td>\n",
              "      <td>0.678939</td>\n",
              "      <td>0.289354</td>\n",
              "      <td>0.559515</td>\n",
              "      <td>0.402727</td>\n",
              "      <td>0.415489</td>\n",
              "      <td>0.311911</td>\n",
              "      <td>0.014739</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.941878</td>\n",
              "      <td>0.765304</td>\n",
              "      <td>0.868484</td>\n",
              "      <td>0.213661</td>\n",
              "      <td>0.765647</td>\n",
              "      <td>0.275559</td>\n",
              "      <td>0.266803</td>\n",
              "      <td>0.789434</td>\n",
              "      <td>0.414999</td>\n",
              "      <td>0.507585</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559734</td>\n",
              "      <td>0.510277</td>\n",
              "      <td>0.662607</td>\n",
              "      <td>0.223826</td>\n",
              "      <td>0.614245</td>\n",
              "      <td>0.389197</td>\n",
              "      <td>0.417669</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0.004807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.938617</td>\n",
              "      <td>0.776520</td>\n",
              "      <td>0.864251</td>\n",
              "      <td>0.269796</td>\n",
              "      <td>0.762975</td>\n",
              "      <td>0.263984</td>\n",
              "      <td>0.268968</td>\n",
              "      <td>0.782484</td>\n",
              "      <td>0.490950</td>\n",
              "      <td>0.524303</td>\n",
              "      <td>...</td>\n",
              "      <td>0.561327</td>\n",
              "      <td>0.547271</td>\n",
              "      <td>0.663392</td>\n",
              "      <td>0.401270</td>\n",
              "      <td>0.566343</td>\n",
              "      <td>0.507497</td>\n",
              "      <td>0.420561</td>\n",
              "      <td>0.317490</td>\n",
              "      <td>0.002724</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>0.756448</td>\n",
              "      <td>0.873531</td>\n",
              "      <td>0.666991</td>\n",
              "      <td>0.160317</td>\n",
              "      <td>0.729603</td>\n",
              "      <td>0.236810</td>\n",
              "      <td>0.235393</td>\n",
              "      <td>0.863749</td>\n",
              "      <td>0.528729</td>\n",
              "      <td>0.598850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.564920</td>\n",
              "      <td>0.515249</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.313600</td>\n",
              "      <td>0.658558</td>\n",
              "      <td>0.466291</td>\n",
              "      <td>0.433929</td>\n",
              "      <td>0.329840</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>0.945845</td>\n",
              "      <td>0.766677</td>\n",
              "      <td>0.872678</td>\n",
              "      <td>0.219189</td>\n",
              "      <td>0.771561</td>\n",
              "      <td>0.273661</td>\n",
              "      <td>0.265504</td>\n",
              "      <td>0.788548</td>\n",
              "      <td>0.482925</td>\n",
              "      <td>0.488530</td>\n",
              "      <td>...</td>\n",
              "      <td>0.564933</td>\n",
              "      <td>0.553154</td>\n",
              "      <td>0.665619</td>\n",
              "      <td>0.245298</td>\n",
              "      <td>0.543855</td>\n",
              "      <td>0.360884</td>\n",
              "      <td>0.417775</td>\n",
              "      <td>0.312038</td>\n",
              "      <td>0.000965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>0.990905</td>\n",
              "      <td>0.764080</td>\n",
              "      <td>0.781102</td>\n",
              "      <td>0.227202</td>\n",
              "      <td>0.783425</td>\n",
              "      <td>0.293496</td>\n",
              "      <td>0.263547</td>\n",
              "      <td>0.792985</td>\n",
              "      <td>0.477677</td>\n",
              "      <td>0.498692</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565220</td>\n",
              "      <td>0.537005</td>\n",
              "      <td>0.664877</td>\n",
              "      <td>0.468492</td>\n",
              "      <td>0.592823</td>\n",
              "      <td>0.411176</td>\n",
              "      <td>0.416593</td>\n",
              "      <td>0.312585</td>\n",
              "      <td>0.002642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>0.954209</td>\n",
              "      <td>0.772856</td>\n",
              "      <td>0.849587</td>\n",
              "      <td>0.282508</td>\n",
              "      <td>0.763172</td>\n",
              "      <td>0.269291</td>\n",
              "      <td>0.261175</td>\n",
              "      <td>0.792671</td>\n",
              "      <td>0.476287</td>\n",
              "      <td>0.500464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565755</td>\n",
              "      <td>0.547353</td>\n",
              "      <td>0.663008</td>\n",
              "      <td>0.398836</td>\n",
              "      <td>0.545958</td>\n",
              "      <td>0.514746</td>\n",
              "      <td>0.418520</td>\n",
              "      <td>0.315245</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>0.949232</td>\n",
              "      <td>0.765256</td>\n",
              "      <td>0.849601</td>\n",
              "      <td>0.229488</td>\n",
              "      <td>0.765632</td>\n",
              "      <td>0.256488</td>\n",
              "      <td>0.274963</td>\n",
              "      <td>0.780938</td>\n",
              "      <td>0.479528</td>\n",
              "      <td>0.489782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565688</td>\n",
              "      <td>0.540031</td>\n",
              "      <td>0.671029</td>\n",
              "      <td>0.383420</td>\n",
              "      <td>0.551319</td>\n",
              "      <td>0.291786</td>\n",
              "      <td>0.416466</td>\n",
              "      <td>0.313401</td>\n",
              "      <td>0.008446</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0c0263e-482b-46ae-9417-11f358a9ea80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0c0263e-482b-46ae-9417-11f358a9ea80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0c0263e-482b-46ae-9417-11f358a9ea80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove class target from features data\n",
        "y = df[\"class\"].values\n",
        "X = df.drop(columns=\"class\").values"
      ],
      "metadata": {
        "id": "HXEZAyyqqnkv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training/test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "7eEXnoolrVbN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_input_features = len(X_train[0])"
      ],
      "metadata": {
        "id": "w26Im_9etXAv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the deep learning model \n",
        "nn_model = tf.keras.models.Sequential()\n",
        "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=number_input_features))\n",
        "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
        "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "zPWnuSp5ra0s"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the structure of the model\n",
        "nn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ComUYHsflU",
        "outputId": "756ed53d-7364-480a-cf96-47ab827cfab5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 16)                480       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 769\n",
            "Trainable params: 769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Sequential model together and customize metrics\n",
        "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy', tf.keras.metrics.BinaryAccuracy(threshold=.7)])\n"
      ],
      "metadata": {
        "id": "iEZV8bVBsDH5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn_model.fit(X_train, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCgZ1jO5sFej",
        "outputId": "45ea3f7f-21b4-43ce-c7b4-cd7a664a8e97"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0108 - accuracy: 0.9984 - binary_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0042 - accuracy: 0.9992 - binary_accuracy: 0.9991\n",
            "Epoch 3/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0038 - accuracy: 0.9993 - binary_accuracy: 0.9993\n",
            "Epoch 4/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0037 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 5/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0035 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 6/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0036 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 7/100\n",
            "6676/6676 [==============================] - 10s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 8/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0035 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 9/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 10/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0035 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 11/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0035 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 12/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 13/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 14/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 15/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 16/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 17/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 18/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 19/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 20/100\n",
            "6676/6676 [==============================] - 10s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 21/100\n",
            "6676/6676 [==============================] - 10s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 22/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 23/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 24/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 25/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 26/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 27/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 28/100\n",
            "6676/6676 [==============================] - 10s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 29/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 30/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 31/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 32/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 33/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 34/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 35/100\n",
            "6676/6676 [==============================] - 10s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 36/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 37/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 38/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 39/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 40/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 41/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 42/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 43/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9993\n",
            "Epoch 44/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 45/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 46/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 47/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 48/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 49/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 50/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 51/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 52/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 53/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 54/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 55/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 56/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 57/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 58/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 59/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 60/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 61/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 62/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 63/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 64/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 65/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 66/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 67/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 68/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0031 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 69/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 70/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 71/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 72/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 73/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 74/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 75/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 76/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 77/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 78/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 79/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9995\n",
            "Epoch 80/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0031 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 81/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 82/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 83/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 84/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0029 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 85/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 86/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 87/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 88/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9995\n",
            "Epoch 89/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 90/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 91/100\n",
            "6676/6676 [==============================] - 10s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 92/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 93/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 94/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 95/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 96/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9995\n",
            "Epoch 97/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 98/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9994 - binary_accuracy: 0.9994\n",
            "Epoch 99/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n",
            "Epoch 100/100\n",
            "6676/6676 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 0.9994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_accuracy = best_model.evaluate(X_test,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCBA6fYZqz0E",
        "outputId": "fa0605cc-9e6c-4088-d5ec-c1f522ba5446"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2226/2226 - 2s - loss: 0.0035 - accuracy: 0.9991 - binary_accuracy: 0.9988 - 2s/epoch - 968us/step\n",
            "Loss: nan, Accuracy: [0.003486975561827421, 0.9990730881690979, 0.9988343119621277]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a method that creates a new Sequential model with hyperparameter options\n",
        "def create_model(hp):\n",
        "    nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
        "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
        "    \n",
        "    # Allow kerastuner to decide number of neurons in first layer\n",
        "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
        "        min_value=1,\n",
        "        max_value=25,\n",
        "        step=2), activation=activation, input_dim=number_input_features))\n",
        "\n",
        "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 6)):\n",
        "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "            min_value=1,\n",
        "            max_value=25,\n",
        "            step=2),\n",
        "            activation=activation))\n",
        "    \n",
        "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    # Compile the model\n",
        "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy', tf.keras.metrics.BinaryAccuracy(threshold=.7)])\n",
        "    \n",
        "    return nn_model"
      ],
      "metadata": {
        "id": "Tr7r5jH-zxkx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLGwZMxg3Ym1",
        "outputId": "cccd43ef-ec1e-4f6e-df6b-89fd51feab37"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.30.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.18.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the kerastuner library\n",
        "import keras_tuner as kt\n",
        "tuner = kt.Hyperband(\n",
        "    create_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=50,\n",
        "    hyperband_iterations=2)"
      ],
      "metadata": {
        "id": "ZbiWhHzb12U5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the kerastuner search for best hyperparameters\n",
        "tuner.search(X_train,y_train,epochs=20,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "rOuAZLbR2l3V"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best model hyperparameters\n",
        "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
        "best_hyper.values"
      ],
      "metadata": {
        "id": "gO2QAvkF-Lk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bce228-347b-4e8e-a529-127a1e68f072"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'first_units': 23,\n",
              " 'num_layers': 2,\n",
              " 'units_0': 21,\n",
              " 'units_1': 23,\n",
              " 'units_2': 7,\n",
              " 'units_3': 1,\n",
              " 'units_4': 19,\n",
              " 'units_5': 21,\n",
              " 'tuner/epochs': 50,\n",
              " 'tuner/initial_epoch': 17,\n",
              " 'tuner/bracket': 2,\n",
              " 'tuner/round': 2,\n",
              " 'tuner/trial_id': '0068'}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ZOoRxRubht-B"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best model against full test data\n",
        "best_model = tuner.get_best_models(1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzH2I8UjUzdr",
        "outputId": "75f23f6e-5d66-40d1-f5c2-b97e2793acf4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_accuracy = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLfEUhA7kamg",
        "outputId": "a9d5004e-f15d-41d0-ede9-26d099620903"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2226/2226 - 2s - loss: 0.0035 - accuracy: 0.9991 - binary_accuracy: 0.9988 - 2s/epoch - 1ms/step\n",
            "Loss: nan, Accuracy: [0.003486975561827421, 0.9990730881690979, 0.9988343119621277]\n"
          ]
        }
      ]
    }
  ]
}